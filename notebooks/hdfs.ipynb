{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env USERNAME=<username>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** Remember that for interacting with EDI Big Data Stack you must be authenticated at the system using kinit command. For more information, read the documentation at [Authenticating with Kerberos](https://docs.edincubator.eu/big-data-stack/basic-concepts.html#authenticating-with-kerberos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kinit -kt ~/work/$USERNAME.service.keytab $USERNAME@EDINCUBATOR.EU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDFS\n",
    "\n",
    "Hadoop Distributed File System (HDFS) is the de-facto file system used at Hadoop environments, and is the one available at EDI Big Data Stack. At this guide, we explain basic commands to manipulate files and directories in HDFS.\n",
    "\n",
    "From a terminal at Jupyter Notebook, you can create and upload files to your HDFS workspace. Every selected team at EDI has its own workspace at /user/<username> directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -mkdir /user/$USERNAME/test\n",
    "hdfs dfs -ls /user/${USERNAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "touch foo\n",
    "hdfs dfs -put foo /user/$USERNAME/test\n",
    "hdfs dfs -ls /user/$USERNAME/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm foo\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -get /user/$USERNAME/test/foo .\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the command for manipulating files and directories at HDFS is hdfs dfs. Indistinctly, you can use hadoop fs command too. The complete description of all the operations provided by this command is available at [Apache Hadoop File System Shell Guide](https://hadoop.apache.org/docs/r3.1.0/hadoop-project-dist/hadoop-common/FileSystemShell.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can also manage files and folders at HDFS using the [Files View (WebHDFS)](https://edi-docs.apps.openshift.deustotech.eu/big-data-stack/tools/views.html#webhdfs)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
